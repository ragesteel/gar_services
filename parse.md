# Получение, импорт, актуализация данных ГАР

NB разумеется пока это похоже больше на эксперименты со Spring'ом, ибо всё ещё находиться в состоянии разработки. 

## Получение архивов выгрузок

Для обработки адресных данных нужно сначала получить их выгрузку. Можно ли самостоятельно пойти [скачать файлы](https://fias.nalog.ru/Frontend) или воспользоваться веб-сервисом, который отдаст нужный URL. А вот каких-либо средств для скачивания файла тут нет. Полный gar_xml на начало осени 2025-го весит 47 Гб, т.е. даже в идеальном случае на интернете со скорость 50 Мбит/с будет скачиваться больше двух часов. Хорошо что помимо полного архива есть и дельта.

### Работа с данными выгрузок

Чтобы не распаковывать архив (и не превращать архив на 47 Гб в отдельные файлы общим объёмом 361 Гб) сделан класс для обработки архива — `GarZipFile`. 

Все поддерживаем разновидности элементов находятся в пакете `ru.gt2.gar.parser.domain`. Для запуска обработки нужно создать два объекта — `XMLStreamProcessor` одним из его статических методов и обработчик — экземпляр `Consumer`, куда в процессе будут отправлять списки записей в процессе их обработки. 

## Источник вдохновения

На Хабр была статья Евгения Ляшева [Универсальный загрузчик XML на java. Или как загрузить файлы ГАР на 250 гб и остаться при памяти](https://habr.com/ru/articles/724324/). Помимо кода в самой статье, есть ещё и [проект `XmlReaderGar` на github](https://github.com/lyashov/XmlReaderGar). 

## Разработчику на заметку

Для организации запускаемых классов с контекстом Spring — смотреть в сторону интерфейса CommandLineRunner.

Доклад с JPoint: [Многопоточная вставка данных в БД](https://www.youtube.com/watch?v=60qHJSnfhmM). Прямо сейчас это не нужно, пусть пока побудет тут.

## Возможные доработки

### Микросервис для скачивания архивов выгрузок.
У него минимальная БД — там только таблица с выгрузками, которая актуализируется по данным с сервиса и таблица с информацией о скачивании файлов. Так он по идее должен по планировщику ходить и обновлять информацию о загрузках и принимать запросы на начало загрузки. А по окончании загрузки он мог-бы событие отправлять.

## Вехи разработки

### 2025-09-02 15:13 MSK 

Проект должен был называться gar-import, но import — это ключевое слово в java, а писать imprt в имени пакета не хотелось, по-этому пусть будет parse!

### 2025-09-02 16:35 MSK 

Среди всего многообразия code-review по `XMLAttributeReader` в [комментариях на хабре](https://habr.com/ru/articles/724324/comments/) никто не сказал что можно сделать его реализующим интерфейс `Iterable<List<T>` чтобы потом можно было со `Steam`'ами играться.

### 2025-09-03 23:23 MSK

Однако `ADM_HIERARCHY` уже прям напрашивается на многопоточную обработку. Но это не самое больше в обработке. Суммарный объем распакованных файлов — больше 38 гигов.

Сейчас вот уже 10 минут прошло. И непонятно сколько ещё будет… однако больше 13 минут. Но это на 143 905 004 элементов. И пока всё без ошибок.

### 2025-09-04 13:10 MSK

Всё-таки классная штука, этот ваш AI, сейчас Cursor мне буквально за 10 минут переписал коментарии которые я писал к полям record'а в в виде `@param`ов основного комментария!

### 2025-09-04 13:35 MSK

Добавление типов с Cursor'ом тоже происходит быстрее!
